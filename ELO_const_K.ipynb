{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "qSeNwVzbdwGx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CwcrYRvSdoXk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Cleaning"
      ],
      "metadata": {
        "id": "kpRpw9AEfJFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of file paths for the data from 2005 to 2019\n",
        "\n",
        "file_paths = [\n",
        "\n",
        "    '/content/drive/MyDrive/Betting_data/2005.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2006.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2007.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2008.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2009.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2010.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2011.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2012.xls',\n",
        "    '/content/drive/MyDrive/Betting_data/2013.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2014.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2015.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2016.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2017.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2018.xlsx',\n",
        "    '/content/drive/MyDrive/Betting_data/2019.xlsx'\n",
        "]\n",
        "\n",
        "# Initializing an empty list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Loading data into a DataFrame\n",
        "for file_path in file_paths:\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_excel(file_path)\n",
        "        data_frames.append(df)\n",
        "    else:\n",
        "        print(f\"File {file_path} not found.\")\n",
        "\n",
        "# Combining all the DataFrames into a single DataFrame\n",
        "betting_df = pd.concat(data_frames, ignore_index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5iSY3njeCca",
        "outputId": "9ce0cf14-1d2e-4b9a-be3f-e964d7bc9b2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting Columns and Data Cleaning\n",
        "\n",
        "# Converting 'Date' into a datetime object\n",
        "betting_df[\"Date\"] = pd.to_datetime(betting_df[\"Date\"], errors='coerce')\n",
        "\n",
        "# Selecting only the relevant columns\n",
        "columns = [\n",
        "    \"Date\",\n",
        "    \"Tournament\",\n",
        "    \"Surface\",\n",
        "    \"Winner\",\n",
        "    \"Loser\",\n",
        "    \"WRank\",\n",
        "    \"WPts\",\n",
        "    \"LRank\",\n",
        "    \"LPts\",\n",
        "    \"B365W\",\n",
        "    \"B365L\",\n",
        "    \"PSW\",\n",
        "    \"PSL\"\n",
        "]\n",
        "betting_df = betting_df[columns]\n",
        "\n",
        "# Converting categorical columns to 'category' data type\n",
        "categorical_columns = [\"Tournament\", \"Surface\"]\n",
        "betting_df[categorical_columns] = betting_df[categorical_columns].astype(\"category\")\n",
        "\n",
        "# Handling missing values in 'WRank' and 'LRank'\n",
        "betting_df[\"WRank\"] = betting_df[\"WRank\"].fillna(100000)\n",
        "betting_df[\"LRank\"] = betting_df[\"LRank\"].fillna(100000)\n",
        "\n",
        "# Handling missing values in 'WPts' and 'LPts' by imputing with the median\n",
        "betting_df[\"WPts\"] = betting_df[\"WPts\"].fillna(betting_df[\"WPts\"].median())\n",
        "betting_df[\"LPts\"] = betting_df[\"LPts\"].fillna(betting_df[\"LPts\"].median())\n",
        "\n",
        "# Removing remaining NaN values\n",
        "betting_df.dropna(inplace=True)\n",
        "\n",
        "# Creating a higher-ranked player column\n",
        "betting_df[\"higher_rank_won\"] = betting_df[\"WRank\"] < betting_df[\"LRank\"]\n",
        "\n",
        "# Calculating the difference in ranking points between the higher and lower-ranked players\n",
        "betting_df[\"diff\"] = (\n",
        "    betting_df[\"WPts\"] * betting_df[\"higher_rank_won\"] +\n",
        "    betting_df[\"LPts\"] * (~betting_df[\"higher_rank_won\"])\n",
        ") - (\n",
        "    betting_df[\"LPts\"] * betting_df[\"higher_rank_won\"] +\n",
        "    betting_df[\"WPts\"] * (~betting_df[\"higher_rank_won\"])\n",
        ")\n",
        "\n",
        "# Print the last few rows of the DataFrame to verify the output\n",
        "print(betting_df.tail())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBZrDQyteBrB",
        "outputId": "e118d546-f740-44d9-9db6-32576b2db55c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Date   Tournament Surface         Winner          Loser  WRank  \\\n",
            "40385 2019-11-15  Masters Cup    Hard      Nadal R.   Tsitsipas S.     1.0   \n",
            "40386 2019-11-15  Masters Cup    Hard     Zverev A.    Medvedev D.     7.0   \n",
            "40387 2019-11-16  Masters Cup    Hard  Tsitsipas S.     Federer R.     6.0   \n",
            "40388 2019-11-16  Masters Cup    Hard      Thiem D.      Zverev A.     5.0   \n",
            "40389 2019-11-17  Masters Cup    Hard  Tsitsipas S.       Thiem D.     6.0   \n",
            "\n",
            "         WPts  LRank    LPts  B365W  B365L   PSW   PSL  higher_rank_won  \\\n",
            "40385  9585.0    6.0  4000.0   1.44   2.75  1.39  3.26             True   \n",
            "40386  2945.0    4.0  5705.0   1.90   1.90  2.14  1.79            False   \n",
            "40387  4000.0    3.0  6190.0   3.50   1.30  3.75  1.33            False   \n",
            "40388  5025.0    7.0  2945.0   1.80   2.00  1.84  2.10             True   \n",
            "40389  4000.0    5.0  5025.0   2.00   1.80  2.00  1.93            False   \n",
            "\n",
            "         diff  \n",
            "40385  5585.0  \n",
            "40386  2760.0  \n",
            "40387  2190.0  \n",
            "40388  2080.0  \n",
            "40389  1025.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-74acefc4b5c3>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  betting_df[categorical_columns] = betting_df[categorical_columns].astype(\"category\")\n",
            "<ipython-input-3-74acefc4b5c3>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  betting_df[\"WRank\"] = betting_df[\"WRank\"].fillna(100000)\n",
            "<ipython-input-3-74acefc4b5c3>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  betting_df[\"LRank\"] = betting_df[\"LRank\"].fillna(100000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting"
      ],
      "metadata": {
        "id": "0v9ebtcnfNvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets based on date\n",
        "split_date = pd.to_datetime(\"2019-01-01\")\n",
        "matches_train = betting_df[betting_df[\"Date\"] < split_date]\n",
        "matches_test = betting_df[betting_df[\"Date\"] >= split_date]\n",
        "\n",
        "# Prepare the features and target variable\n",
        "X_train = matches_train[[\"diff\"]]\n",
        "y_train = matches_train[\"higher_rank_won\"]\n",
        "X_test = matches_test[[\"diff\"]]\n",
        "y_test = matches_test[\"higher_rank_won\"]\n"
      ],
      "metadata": {
        "id": "rzIxrejPeZ0P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the initial Elo rating for all players\n",
        "\n",
        "initial_elo = 1500\n",
        "k_factor = 25  # Constant K-factor\n",
        "\n",
        "# Creating a set of unique player names from 'Winner' and 'Loser'\n",
        "# Union needed to avoid duplicate entries\n",
        "\n",
        "unique_player_names = set(matches_train[\"Winner\"]).union(set(matches_train[\"Loser\"]))\n",
        "\n",
        "# Initialize the Elo ratings dictionary with the initial Elo score\n",
        "elo_ratings = {player_name: initial_elo for player_name in unique_player_names}\n"
      ],
      "metadata": {
        "id": "uCcxQVg4eiAO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELO Functions definition"
      ],
      "metadata": {
        "id": "6vSUVns6fUKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate expected probability based on Elo ratings\n",
        "def calculate_EP(elo_1, elo_2):\n",
        "    return 1 / (1 + 10 ** ((elo_2 - elo_1) / 400))\n",
        "\n",
        "# Function to update Elo ratings based on match outcomes with a constant K-factor\n",
        "def winner_update_elo(current_elo, expected_prob, actual_result, k_factor):\n",
        "    return current_elo + k_factor * (actual_result - expected_prob)\n",
        "\n",
        "def loser_update_elo(current_elo, expected_prob, actual_result, k_factor):\n",
        "    return current_elo + k_factor * (actual_result - (1 - expected_prob))"
      ],
      "metadata": {
        "id": "ZSjxIBvVetMn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updating the ELO ratings for training set"
      ],
      "metadata": {
        "id": "ueMH4oINfaRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Elo ratings using the constant K-factor model\n",
        "for index, row in matches_train.iterrows():\n",
        "    winner_name = row[\"Winner\"]\n",
        "    loser_name = row[\"Loser\"]\n",
        "\n",
        "    # Ensure Elo ratings are initialized correctly to avoid KeyErrors\n",
        "    if winner_name not in elo_ratings:\n",
        "        elo_ratings[winner_name] = initial_elo\n",
        "    if loser_name not in elo_ratings:\n",
        "        elo_ratings[loser_name] = initial_elo\n",
        "\n",
        "    winner_elo = elo_ratings[winner_name]\n",
        "    loser_elo = elo_ratings[loser_name]\n",
        "\n",
        "    expected_win_prob = calculate_EP(winner_elo, loser_elo)\n",
        "\n",
        "    elo_ratings[winner_name] = winner_update_elo(winner_elo, expected_win_prob, 1, k_factor)\n",
        "    elo_ratings[loser_name] = loser_update_elo(loser_elo, expected_win_prob, 0, k_factor)\n"
      ],
      "metadata": {
        "id": "w1iSmPVpe4tI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updating ELO ratings for testing set"
      ],
      "metadata": {
        "id": "DIwUAybJfeOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all players in the test set are also included in the dictionaries\n",
        "for index, row in matches_test.iterrows():\n",
        "    winner_name = row[\"Winner\"]\n",
        "    loser_name = row[\"Loser\"]\n",
        "\n",
        "    if winner_name not in elo_ratings:\n",
        "        elo_ratings[winner_name] = initial_elo\n",
        "\n",
        "    if loser_name not in elo_ratings:\n",
        "        elo_ratings[loser_name] = initial_elo\n",
        "\n",
        "# Calculate expected probabilities for the testing set based on the constant K-factor model\n",
        "expected_prob_test, expected_outcome_test = [], []\n",
        "\n",
        "for index, row in matches_test.iterrows():\n",
        "    winner_name = row[\"Winner\"]\n",
        "    loser_name = row[\"Loser\"]\n",
        "\n",
        "    winner_elo = elo_ratings[winner_name]\n",
        "    loser_elo = elo_ratings[loser_name]\n",
        "\n",
        "    # Calculate expected probability of the winner defeating the loser\n",
        "    expected_win_prob = calculate_EP(winner_elo, loser_elo)\n",
        "\n",
        "    elo_ratings[winner_name] = winner_update_elo(winner_elo, expected_win_prob, 1, k_factor)\n",
        "    elo_ratings[loser_name] = loser_update_elo(loser_elo, expected_win_prob, 0, k_factor)\n",
        "\n",
        "    if row[\"higher_rank_won\"] == 1:\n",
        "        expected_prob_test.append(expected_win_prob)\n",
        "        expected_outcome_test.append(int(expected_win_prob > 0.5))\n",
        "    else:\n",
        "        expected_prob_test.append(1 - expected_win_prob)\n",
        "        expected_outcome_test.append(int((1 - expected_win_prob) > 0.5))\n"
      ],
      "metadata": {
        "id": "vGkyTKZdfBXm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "LBLuzsF6fkoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the actual results for the test set\n",
        "y_test = matches_test[\"higher_rank_won\"].apply(lambda x: 1 if x else 0)  # Ensuring binary labels\n",
        "\n",
        "# Evaluate the ELO model\n",
        "elo_accuracy = accuracy_score(y_test, expected_outcome_test)\n",
        "elo_log_loss = log_loss(y_test, expected_prob_test)\n",
        "elo_calibration = np.sum(expected_prob_test) / np.sum(y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Elo Model Accuracy: {elo_accuracy}\")\n",
        "print(f\"Elo Model Log Loss: {elo_log_loss}\")\n",
        "print(f\"Elo Model Calibration: {elo_calibration}\")\n",
        "\n",
        "# Add ELO model results to validation stats\n",
        "validation_stats = pd.DataFrame({\n",
        "    \"model\": [\"elo_constant_k\"],\n",
        "    \"accuracy\": [elo_accuracy],\n",
        "    \"calibration\": [elo_calibration],\n",
        "    \"log_loss\": [elo_log_loss]\n",
        "})\n",
        "\n",
        "print(validation_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l16rMZ2fFVi",
        "outputId": "bb02aff6-c54c-4b39-f01e-3402089ac7f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elo Model Accuracy: 0.6312524234199302\n",
            "Elo Model Log Loss: 0.6336791627253523\n",
            "Elo Model Calibration: 1.0338132755797784\n",
            "            model  accuracy  calibration  log_loss\n",
            "0  elo_constant_k  0.631252     1.033813  0.633679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing the Model using different K values"
      ],
      "metadata": {
        "id": "oA_DjW_tglbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the initial Elo rating for all players\n",
        "initial_elo = 1500\n",
        "\n",
        "# Creating a set of unique player names from 'Winner' and 'Loser'\n",
        "unique_player_names = set(matches_train[\"Winner\"]).union(set(matches_train[\"Loser\"]))\n",
        "\n",
        "# Initializing the Elo ratings dictionary with the initial Elo score\n",
        "elo_ratings = {player_name: initial_elo for player_name in unique_player_names}"
      ],
      "metadata": {
        "id": "Bxh1Zftlgtgz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the ELO model with different K values\n",
        "\n",
        "def evaluate_elo_model(k_factor):\n",
        "\n",
        "    # Initialize Elo ratings again to start fresh for each K-factor\n",
        "\n",
        "    elo_ratings = {player_name: initial_elo for player_name in unique_player_names}\n",
        "\n",
        "    # Update Elo ratings using the constant K-factor model\n",
        "    for index, row in matches_train.iterrows():\n",
        "        winner_name = row[\"Winner\"]\n",
        "        loser_name = row[\"Loser\"]\n",
        "\n",
        "        if winner_name not in elo_ratings:\n",
        "            elo_ratings[winner_name] = initial_elo\n",
        "        if loser_name not in elo_ratings:\n",
        "            elo_ratings[loser_name] = initial_elo\n",
        "\n",
        "        winner_elo = elo_ratings[winner_name]\n",
        "        loser_elo = elo_ratings[loser_name]\n",
        "\n",
        "        expected_win_prob = calculate_EP(winner_elo, loser_elo)\n",
        "\n",
        "        elo_ratings[winner_name] = winner_update_elo(winner_elo, expected_win_prob, 1, k_factor)\n",
        "        elo_ratings[loser_name] = loser_update_elo(loser_elo, expected_win_prob, 0, k_factor)\n",
        "\n",
        "\n",
        "    for index, row in matches_test.iterrows():\n",
        "        winner_name = row[\"Winner\"]\n",
        "        loser_name = row[\"Loser\"]\n",
        "\n",
        "        if winner_name not in elo_ratings:\n",
        "            elo_ratings[winner_name] = initial_elo\n",
        "\n",
        "        if loser_name not in elo_ratings:\n",
        "            elo_ratings[loser_name] = initial_elo\n",
        "\n",
        "    # Calculating expected probabilities for the testing set based on the constant K-factor model\n",
        "    expected_prob_test, expected_outcome_test = [], []\n",
        "\n",
        "    for index, row in matches_test.iterrows():\n",
        "        winner_name = row[\"Winner\"]\n",
        "        loser_name = row[\"Loser\"]\n",
        "\n",
        "        winner_elo = elo_ratings[winner_name]\n",
        "        loser_elo = elo_ratings[loser_name]\n",
        "\n",
        "        expected_win_prob = calculate_EP(winner_elo, loser_elo)\n",
        "\n",
        "        elo_ratings[winner_name] = winner_update_elo(winner_elo, expected_win_prob, 1, k_factor)\n",
        "        elo_ratings[loser_name] = loser_update_elo(loser_elo, expected_win_prob, 0, k_factor)\n",
        "\n",
        "        if row[\"higher_rank_won\"] == 1:\n",
        "            expected_prob_test.append(expected_win_prob)\n",
        "            expected_outcome_test.append(int(expected_win_prob > 0.5))\n",
        "        else:\n",
        "            expected_prob_test.append(1 - expected_win_prob)\n",
        "            expected_outcome_test.append(int((1 - expected_win_prob) > 0.5))\n",
        "\n",
        "    y_test = matches_test[\"higher_rank_won\"].apply(lambda x: 1 if x else 0)\n",
        "\n",
        "    # Evaluating the ELO model\n",
        "    elo_accuracy = accuracy_score(y_test, expected_outcome_test)\n",
        "    elo_log_loss = log_loss(y_test, expected_prob_test)\n",
        "    elo_calibration = np.sum(expected_prob_test) / np.sum(y_test)\n",
        "\n",
        "    return elo_accuracy, elo_log_loss, elo_calibration\n"
      ],
      "metadata": {
        "id": "FmSFpUZMhBB-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Range of K values\n",
        "k_values = [10, 15, 20, 25, 30, 35, 40]\n",
        "\n",
        "# Empty list to Store results\n",
        "results = []\n",
        "\n",
        "for k in k_values:\n",
        "    accuracy, log_loss_value, calibration = evaluate_elo_model(k)\n",
        "    results.append({\n",
        "        \"k_factor\": k,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"log_loss\": log_loss_value,\n",
        "        \"calibration\": calibration\n",
        "    })\n",
        "\n",
        "# Converting results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Finding the best K-factor based on the desired metric\n",
        "best_result = results_df.loc[results_df[\"log_loss\"].idxmax()]\n",
        "\n",
        "print(\"Best K-factor based on log_loss:\")\n",
        "print(best_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L5NvmbUhTBk",
        "outputId": "4fd85e84-dbaa-4138-ac89-4393ea5d4096"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K-factor based on log_loss:\n",
            "k_factor       40.000000\n",
            "accuracy        0.632416\n",
            "log_loss        0.638343\n",
            "calibration     1.050368\n",
            "Name: 6, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_k_factor = best_result[\"k_factor\"]\n",
        "best_accuracy, best_log_loss, best_calibration = evaluate_elo_model(best_k_factor)\n",
        "\n",
        "# Print final model evaluation with the best K-factor\n",
        "print(f\"Best K-factor: {best_k_factor}\")\n",
        "print(f\"Final Elo Model Accuracy: {best_accuracy}\")\n",
        "print(f\"Final Elo Model Log Loss: {best_log_loss}\")\n",
        "print(f\"Final Elo Model Calibration: {best_calibration}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuDts3WMh3B-",
        "outputId": "4ef4c4f8-5bc7-48e9-a702-6fae33f1eac3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K-factor: 40.0\n",
            "Final Elo Model Accuracy: 0.6324156649864289\n",
            "Final Elo Model Log Loss: 0.6383433765724233\n",
            "Final Elo Model Calibration: 1.050368017361009\n"
          ]
        }
      ]
    }
  ]
}